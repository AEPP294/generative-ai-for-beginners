# 画像生成アプリケーションの構築

[![画像生成アプリケーションの構築](../../images/09-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](TBD)

> ビデオ近日公開予定

LLMにはテキスト生成以外の機能もある。テキスト記述から画像を生成することも可能だ。モダリティとして画像を持つことは、医療技術、建築、観光、ゲーム開発など、多くの分野で非常に有用です。この章では、最も人気のある2つの画像生成モデル、DALL-EとMidjourneyについて見ていきます。

## はじめに

このレッスンでは

- 画像生成と、なぜそれが便利なのか。
- DALL-E と Midjourney とは何か、そしてどのように機能するのか。
- 画像生成アプリの作り方。

## 学習目標

このレッスンを修了すると、以下のことができるようになります：

- 画像生成アプリケーションを構築する。
- メタプロンプトを使ってアプリケーションの境界を定義する。
- DALL-EとMidjourneyとの連携。

## なぜ画像生成アプリケーションを作るのか？

画像生成アプリケーションは、生成AIの能力を探求する素晴らしい方法です。例えば、以下のような用途に使用できます：  

- **画像編集と合成**。画像編集や画像合成など、さまざまなユースケースの画像を生成できます。 

- **様々な産業への応用**。医療技術、観光、ゲーム開発など、さまざまな業界の画像生成にも使用できます。

## シナリオ Edu4All

このレッスンの一環として、スタートアップ企業であるEdu4Allと引き続き連携します。生徒たちは評価用の画像を作成します。具体的にどのような画像を作成するかは生徒次第ですが、自分のおとぎ話の挿絵にしたり、物語の新しいキャラクターを作成したり、自分のアイデアやコンセプトを視覚化するのに役立てたりします。

例えば、Edu4Allの生徒がモニュメントについて授業で取り組んでいる場合、このような画像を作成することができる：

![Edu4Allスタートアップ、モニュメントに関する授業、エッフェル塔](../../images/startup.png?WT.mc_id=academic-105485-koreyst)

のようなプロンプトを使って

> "早朝のエッフェル塔の横の犬"

## DALL-E と Midjourney とは？

[DALL-E](https://openai.com/dall-e-2?WT.mc_id=academic-105485-koreyst)と[Midjourney](https://www.midjourney.com/?WT.mc_id=academic-105485-koreyst)は、最もポピュラーな画像生成モデルの2つで、プロンプトを使って画像を生成することができます。

### DALL-E

DALL-Eから始めましょう。DALL-Eは、テキスト記述から画像を生成する生成AIモデルです。

> [DALL-EはCLIPとdiffused attentionという2つのモデルの組み合わせです](https://towardsdatascience.com/openais-dall-e-and-clip-101-a-brief-introduction-3a4367280d4e?WT.mc_id=academic-105485-koreyst)。 

- **CLIP**は、画像やテキストからデータの数値表現であるエンベッディングを生成するモデルです。 

- **Diffused attention**は、エンベッディングから画像を生成するモデルです。DALL-Eは、画像とテキストのデータセットに対して学習され、テキスト記述から画像を生成するために利用することができます。例えば、帽子をかぶった猫や、モヒカンの犬の画像を生成することができます。

### Midjourney 

Midjourney は DALL-E と同様に、テキストプロンプトから画像を生成します。Midjourney は、「帽子をかぶった猫」や「モヒカンの犬」のようなプロンプトを使って画像を生成することもできます。

![Midjourneyによって生成された画像、機械仕掛けのハト](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png/440px-Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png)

*Image cred Wikipedia, image generated by Midjourney*

## DALL-EとMidjourneyの仕組み

まず、[DALL-E](https://arxiv.org/pdf/2102.12092.pdf?WT.mc_id=academic-105485-koreyst)。DALL-E は、*自己回帰変換器* を用いた変換器アーキテクチャに基づく生成 AI モデルです。 

自己回帰変換器(*autoregressive transformer)*は、モデルがテキスト記述からどのように画像を生成するかを定義するもので、一度に1つのピクセルを生成し、生成されたピクセルを使って次のピクセルを生成します。画像が完成するまで、ニューラルネットワークの複数のレイヤーを通過する。 

このようなプロセスで、DALL-Eは、生成した画像の属性、オブジェクト、特性などを制御する。しかし、DALL-E 2 と 3 では、生成される画像に対してより多くの制御が可能です、  

## 最初の画像生成アプリケーションを作る

では、画像生成アプリケーションを作るには何が必要でしょうか？以下のライブラリが必要です：

- **python-dotenv**は、コードから離れた*.env*ファイルに秘密を保持するために、このライブラリを使用することを強くお勧めします。
- **openai**、このライブラリはOpenAIのAPIとやりとりするために使います。
- **pillow**：Pythonで画像を扱うためのライブラリです。
- **requests**は、HTTPリクエストを行うためのものです。

1. 以下の内容でファイル *.env* を作成する：

    ```text
    AZURE_OPENAI_ENDPOINT=<your endpoint>
    AZURE_OPENAI_KEY=<your key>
    ```

    リソースの Azure Portal の「Keys and Endpoint」セクションで、この情報を見つけます。

1. 上記のライブラリを*requirements.txt*というファイルに以下のようにまとめる：

    ```text
    python-dotenv
    openai
    pillow
    requests
    ```

1. 次に、仮想環境を作成し、ライブラリをインストールする：

    ```bash
    python3 -m venv venv
    source venv/bin/activate
    pip install -r requirements.txt
    ```

    Windowsの場合は、以下のコマンドを使用して仮想環境を作成し、アクティブ化します：

    ```bash
    python3 -m venv venv
    venv\Scripts\activate.bat
    ````

1. *app.py*というファイルに以下のコードを追加します：

    ```python
    import openai
    import os
    import requests
    from PIL import Image
    import dotenv
    
    # import dotenv
    dotenv.load_dotenv()
    
    # Get endpoint and key from environment variables
    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']
    openai.api_key = os.environ['AZURE_OPENAI_KEY']     
    
    # Assign the API version (DALL-E is currently supported for the 2023-06-01-preview API version only)
    openai.api_version = '2023-06-01-preview'
    openai.api_type = 'azure'
    
    
    try:
        # Create an image by using the image generation API
        generation_response = openai.Image.create(
            prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here
            size='1024x1024',
            n=2,
            temperature=0,
        )
        # Set the directory for the stored image
        image_dir = os.path.join(os.curdir, 'images')
    
        # If the directory doesn't exist, create it
        if not os.path.isdir(image_dir):
            os.mkdir(image_dir)
    
        # Initialize the image path (note the filetype should be png)
        image_path = os.path.join(image_dir, 'generated-image.png')
    
        # Retrieve the generated image
        image_url = generation_response["data"][0]["url"]  # extract image URL from response
        generated_image = requests.get(image_url).content  # download the image
        with open(image_path, "wb") as image_file:
            image_file.write(generated_image)
    
        # Display the image in the default image viewer
        image = Image.open(image_path)
        image.show()
    
    # catch exceptions
    except openai.error.InvalidRequestError as err:
        print(err)

    ```

このコードを説明しよう：

- まず、OpenAIライブラリ、dotenvライブラリ、requestsライブラリ、Pillowライブラリなど、必要なライブラリをインポートする。

    ```python
    import openai
    import os
    import requests
    from PIL import Image
    import dotenv
    ```

- 次に、*.env*ファイルから環境変数をロードする。

    ```python
    # import dotenv
    dotenv.load_dotenv()
    ```

- その後、エンドポイント、OpenAI APIのキー、バージョン、タイプを設定する。

    ```python
    # Get endpoint and key from environment variables
    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']
    openai.api_key = os.environ['AZURE_OPENAI_KEY'] 

    # add version and type, Azure specific
    openai.api_version = '2023-06-01-preview'
    openai.api_type = 'azure'
    ```

- 次に、画像を生成する：

    ```python
    # Create an image by using the image generation API
    generation_response = openai.Image.create(
        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here
        size='1024x1024',
        n=2,
        temperature=0,
    )
    ```

    上記のコードは、生成された画像のURLを含むJSONオブジェクトで応答します。このURLを使って画像をダウンロードし、ファイルに保存することができる。

- 最後に、画像を開き、標準の画像ビューアを使って表示します：

    ```python
    image = Image.open(image_path)
    image.show()
    ```

### 画像生成の詳細

画像を生成するコードをさらに詳しく見てみよう：

```python
generation_response = openai.Image.create(
        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here
        size='1024x1024',
        n=2,
        temperature=0,
    )
```


- **プロンプト**は、画像を生成するために使用されるテキストプロンプトです。この場合、"Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils "というプロンプトを使っています。
- **size**は生成される画像のサイズです。この場合、1024x1024ピクセルの画像を生成します。
- **n**は生成される画像の数です。ここでは2枚の画像を生成している。
- **temperature**は生成AIモデルの出力のランダム性を制御するパラメータです。温度は0と1の間の値で、0は出力が決定論的であることを意味し、1は出力がランダムであることを意味する。デフォルト値は0.7である。

画像を使ってできることは他にもありますが、それは次のセクションで説明します。

## 画像生成の追加機能

ここまで、Pythonの数行で画像を生成する方法を見てきました。しかし、画像を使ってできることはまだまだあります。

以下のようなこともできます：

- **編集の実行**。既存の画像にマスクとプロンプトを与えることで、画像を変更することができます。例えば、画像の一部に何かを追加することができます。例えば、ウサギの画像に帽子を追加することができます。そのためには、画像、マスク（変更する部分を特定するもの）、テキストプロンプトを提供します。

    ```python
    response = openai.Image.create_edit(
      image=open("base_image.png", "rb"),
      mask=open("mask.png", "rb"),
      prompt="An image of a rabbit with a hat on its head.",
      n=1,
      size="1024x1024"
    )
    image_url = response['data'][0]['url']
    ```

    ベースとなる画像はウサギだけですが、最終的な画像はウサギに帽子をかぶせたものになります。

- **バリエーションを作る**。このアイデアは、既存の画像を使用して、バリエーションを作成するように依頼することです。バリエーションを作成するには、画像とテキストプロンプト、そしてこのようなコードを提供します：

    ```python
    response = openai.Image.create_variation(
      image=open("bunny-lollipop.png", "rb"),
      n=1,
      size="1024x1024"
    )
    image_url = response['data'][0]['url']
    ```

    > これはOpenAIでのみサポートされています。

## 温度（Temperature）

温度（Temperature）は生成AIモデルの出力のランダム性を制御するパラメータである。温度（Temperature）は0と1の間の値で、0は出力が決定論的であることを意味し、1は出力がランダムであることを意味する。デフォルト値は0.7である。

このプロンプトを2回実行して、温度（Temperature）がどのように機能するかの例を見てみよう：

> プロンプト : "水仙の咲く霧の草原で、ロリポップを持った馬上のウサギ"

![ロリポップを持った馬上のウサギ、バージョン1](../../images/v1-generated-image.png?WT.mc_id=academic-105485-koreyst)

同じ画像が2度表示されないことを確認するために、同じプロンプトを実行してみよう：

![馬に乗ったウサギの生成画像](../../images/v2-generated-image.png?WT.mc_id=academic-105485-koreyst)

ご覧のように、画像は似ているが同じではない。温度（Temperature）の値を0.1に変えて、どうなるか試してみよう：

```python
 generation_response = openai.Image.create(
        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here
        size='1024x1024',
        n=2
    )
```

### 温度（Temperature）を変える

では、反応をより決定論的にしてみよう。生成した2つの画像から、最初の画像にはウサギがいて、2番目の画像には馬がいることが観察できた。

そこで、コードを変更して、温度を0に設定してみよう：

```python
generation_response = openai.Image.create(
        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here
        size='1024x1024',
        n=2,
        temperature=0
    )
```

このコードを実行すると、次の2つの画像が得られる：

- ![Temperature 0, v1](../../images/v1-temp-generated-image.png?WT.mc_id=academic-105485-koreyst)
- ![Temperature 0 , v2](../../images/v2-temp-generated-image.png?WT.mc_id=academic-105485-koreyst)

ここでは、画像がより互いに似ていることがよくわかります。

## メタプロンプトを使ってアプリケーションの境界を定義する方法

私たちのデモでは、すでにクライアントのために画像を生成することができます。しかし、アプリケーションの境界線を作る必要があります。 

例えば、仕事で使うには安全でない画像や、子供には不適切な画像は生成したくありません。 

これは*メタプロンプト*で実現できます。メタプロンプトは、生成AIモデルの出力を制御するために使用されるテキストプロンプトです。例えば、メタプロンプトを使用して出力を制御し、生成された画像が仕事用に安全であること、または子供にとって適切であることを保証することができます。

### メタプロンプトはどのように機能するのか？

さて、メタプロンプトはどのように機能するのだろうか？

メタプロンプトは生成AIモデルの出力を制御するために使用されるテキストプロンプトで、テキストプロンプトの前に配置され、モデルの出力を制御するために使用され、モデルの出力を制御するためにアプリケーションに埋め込まれます。プロンプト入力とメタプロンプト入力を単一のテキストプロンプトにカプセル化する。

メタプロンプトの一例は以下のようになる：

```text
あなたは子供向けの画像を作成するアシスタントデザイナーです。

画像は仕事上安全で、子供たちに適切である必要があります。

画像はカラーである必要があります。 

画像は横向きである必要があります。 

画像は16:9のアスペクト比である必要があります。

仕事上安全でない、または子供にとって適切でない以下の入力は考慮しないでください。

(入力) 

```text

では、デモでメタ・プロンプトをどのように使うかを見てみよう。

```python
disallow_list = "剣、暴力、血、血糊、ヌード、性的内容、成人向け内容、成人向けテーマ、成人向け言語、成人向けユーモア、成人向けジョーク、成人向け状況、成人向け"

meta_prompt =f"""あなたは子供向けの画像を作成するアシスタントデザイナーです。

画像は仕事上安全で、子供たちに適切である必要があります。

画像はカラーである必要があります。 

画像は横向きである必要があります。 

画像は16:9のアスペクト比である必要があります。

仕事上安全でない、または子供にとって適切でない以下の入力は考慮しないでください。
{disallow_list}
"""

prompt = f"{meta_prompt} 
馬に乗ったウサギがロリポップを持っている画像を作成する"

# TODO 画像を生成するリクエストを追加する
```

上記のプロンプトから、すべての画像がメタプロンプトを考慮して作成されていることがわかる。

## 課題 - 生徒を有効にしよう

このレッスンの最初にEdu4Allを紹介しました。次は学生が評価用の画像を作成できるようにする番です。

どのようなモニュメントを作成するかは学生次第です。生徒はこの課題で創造性を発揮し、これらのモニュメントを異なる文脈に置くよう求められます。

## 解決策

ここに1つの解決策があります：

```python
import openai
import os
import requests
from PIL import Image
import dotenv

# import dotenv
dotenv.load_dotenv()

# Get endpoint and key from environment variables
openai.api_base = "<replace with endpoint>"
openai.api_key = "<replace with api key>"     

# Assign the API version (DALL-E is currently supported for the 2023-06-01-preview API version only)
openai.api_version = '2023-06-01-preview'
openai.api_type = 'azure'
    
disallow_list = "剣、暴力、血、血糊、ヌード、性的内容、成人向け内容、成人向けテーマ、成人向け言語、成人向けユーモア、成人向けジョーク、成人向け状況、成人向け"

meta_prompt = f"""あなたは子供向けの画像を作成するアシスタントデザイナーです。

画像は仕事上安全で、子供たちに適切である必要があります。

画像はカラーである必要があります。 

画像は横向きである必要があります。 

画像は16:9のアスペクト比である必要があります。

仕事上安全でない、または子供にとって適切でない以下の入力は考慮しないでください。
{disallow_list}"""

prompt = f"""{metaprompt}
夕日に照らされたフランス・パリの凱旋門のモニュメントと、それを見つめるテディを抱いた小さな子供。
""""    

try:
    # Create an image by using the image generation API
    generation_response = openai.Image.create(
        prompt=prompt,    # Enter your prompt text here
        size='1024x1024',
        n=2,
        temperature=0,
    )
    # Set the directory for the stored image
    image_dir = os.path.join(os.curdir, 'images')

    # If the directory doesn't exist, create it
    if not os.path.isdir(image_dir):
        os.mkdir(image_dir)

    # Initialize the image path (note the filetype should be png)
    image_path = os.path.join(image_dir, 'generated-image.png')

    # Retrieve the generated image
    image_url = generation_response["data"][0]["url"]  # extract image URL from response
    generated_image = requests.get(image_url).content  # download the image
    with open(image_path, "wb") as image_file:
        image_file.write(generated_image)

    # Display the image in the default image viewer
    image = Image.open(image_path)
    image.show()

# catch exceptions
except openai.error.InvalidRequestError as err:
    print(err)
```


## 素晴らしい仕事！学習を続ける

このレッスンを終えたら、[生成AI学習コレクション](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst)をチェックして、生成AI知識のレベルアップを続けましょう！

レッスン10では、[ローコードでAIアプリケーションを構築する](../10-building-low-code-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)方法を見ていきます。
