# さまざまなLLMを探求し、比較する

[![さまざまなLLMを探求し、比較する](../../images/02-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://youtu.be/J1mWzw0P74c?WT.mc_id=academic-105485-koreyst)

> このレッスンのビデオを見るには上の画像をクリックしてください。

前回のレッスンでは、生成AIがどのようにテクノロジーの展望を変えつつあるのか、大規模言語モデル（LLM）がどのように機能するのか、そして私たちのスタートアップのようなビジネスがどのようにユースケースに適用し、成長できるのかを見てきました！この章では、様々なタイプの大規模言語モデル（LLM）を比較対照し、その長所と短所を理解する。

私たちのスタートアップの旅における次のステップは、大規模言語モデル（LLM）の現在の状況を調査し、私たちのユースケースに適したものを理解することです。

## はじめに

このレッスンでは

- 現在の環境におけるさまざまなタイプのLLM
- Azureでのユースケースに対するさまざまなモデルのテスト、反復、比較。
- LLMのデプロイ方法

## 学習目標

このレッスンを修了すると、以下のことができるようになります：

- ユースケースに適したモデルを選択する
- モデルをテストし、反復し、パフォーマンスを向上させる方法を理解します。
- ビジネスがどのようにモデルを配備するかを理解します。

## 様々なタイプのLLMを理解する

大規模言語モデル（LLM）は、そのアーキテクチャ、トレーニングデータ、ユースケースに基づいて複数の分類が可能です。これらの違いを理解することは、スタートアップがシナリオに適したモデルを選択し、テスト、反復、パフォーマンス向上の方法を理解するのに役立ちます。

LLMモデルには様々な種類があり、どのモデルを選択するかは、使用する目的、データ、支払う用意のある金額などによって異なります。

テキスト、オーディオ、ビデオ、画像生成などにモデルを使用するかどうかによって、異なるタイプのモデルを選ぶことができます。

- **音声・音声認識**。この目的には、汎用的で音声認識を目的としたウィスパー型が最適です。多様な音声で学習され、多言語の音声認識を行うことができます。[Whisper型モデルの詳細はこちら](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst)。

- **画像生成** 画像生成には、DALL-EとMidjourneyの2つがよく知られています。DALL-EはAzure OpenAIが提供しています。[DALL-Eについての詳細はこちら](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst)と、このカリキュラムの第9章にもあります。

- **テキスト生成**。ほとんどのモデルはテキスト生成で学習され、GPT-3.5からGPT-4まで多くの選択肢があります。GPT-4が最も高価である。Azure Open AI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst)を調べて、どのモデルが能力とコストの面で最もニーズに合っているかを評価する価値がある。

モデルを選択するということは、基本的な機能を得るということだが、それだけでは十分ではないかもしれない。多くの場合、LLMに伝える必要のある企業固有のデータがあります。このような場合、どのようにアプローチするかについてはいくつかの選択肢があります。

### ファウンデーション・モデルとLLM

ファウンデーションモデルという用語は[スタンフォード大学の研究者によって作られた](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst)もので、以下のようないくつかの基準に従ったAIモデルとして定義されている：

- **教師なし学習または自己教師あり学習**を使用して学習される。つまり、ラベル付けされていないマルチモーダルデータで学習され、学習プロセスに人間の注釈やデータのラベル付けを必要としない。
- 数十億のパラメータで訓練された非常に深いニューラルネットワークに基づく、**非常に大規模なモデル**である。
- つまり、他のモデルを構築するための出発点として使用することができ、それはfine-tuningによって行うことができる。

![ファウンデーション・モデルとLLMの比較](../../images/FoundationModel.png?WT.mc_id=academic-105485-koreyst)

画像ソース:  [ファウンデーションモデルと大規模言語モデルのエッセンシャルガイド｜Babar M Bhatti著｜Medium
](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

この違いをさらに明確にするために、ChatGPTを例にとってみましょう。ChatGPTの最初のバージョンを構築するために、GPT-3.5と呼ばれるモデルが基礎モデルとして機能しました。つまり、OpenAIはチャット特有のデータを使って、チャットボットのような会話シナリオでのパフォーマンスに特化したGPT-3.5のチューニングバージョンを作成したのです。

![基礎モデル](../../images/Multimodal.png?WT.mc_id=academic-105485-koreyst)

画像ソース: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### オープンソースと独自モデルの比較

LLMを分類するもう一つの方法は、オープンソースか独自モデルかということです。

オープンソースモデルとは、一般に公開され、誰でも利用できるモデルのことです。多くの場合、モデルを作成した企業や研究コミュニティによって公開されています。これらのモデルは、LLMの様々なユースケースのために、検査、修正、カスタマイズが可能です。しかし、これらのモデルは必ずしも実運用に最適化されているわけではなく、独自に開発されたモデルほど性能が高くないこともある。さらに、オープンソースモデルへの資金提供は限られており、長期的なメンテナンスが行われなかったり、最新の研究に更新されなかったりする可能性があります。人気のあるオープンソースモデルの例としては、[Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst)、[Bloom](https://sapling.ai/llm/bloom?WT.mc_id=academic-105485-koreyst)、[LLaMA](https://sapling.ai/llm/llama?WT.mc_id=academic-105485-koreyst)などがある。

独自モデルは、企業が所有し、一般には公開されていないモデルである。これらのモデルは多くの場合、生産用に最適化されている。しかし、異なるユースケースのために検査したり、修正したり、カスタマイズしたりすることは許されていません。さらに、常に無料で利用できるわけではなく、利用するにはサブスクリプションや支払いが必要な場合もある。また、ユーザーはモデルの学習に使用されるデータを管理することができないため、データ・プライバシーとAIの責任ある使用に対するコミットメントを保証するモデルの所有者に委ねる必要がある。一般的な独自モデルの例としては、[OpenAIモデル](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst)、[Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst)、[Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst)などがある。

### エンベッディング対画像生成対テキスト・コード生成

LLMは、生成する出力によっても分類できる。

エンベッディングは、テキストをエンベッディングと呼ばれる入力テキストの数値表現に変換できるモデルの集合です。エンベッディングは、機械が単語やセンテンス間のリレーションシップを理解することを容易にし、分類モデルや数値データに対してより優れた性能を持つクラスタリングモデルなど、他のモデルの入力として消費することができます。埋め込みモデルは、豊富なデータがある代替タスクに対してモデルを構築し、そのモデルの重み（エンベッディング）を他の下流のタスクに再利用する、転移学習によく使われる。このカテゴリの例は、[OpenAIのエンベッディング](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst)です。

![エンベッディング](../../images/Embedding.png?WT.mc_id=academic-105485-koreyst)。

画像生成モデルとは、画像を生成するモデルのことです。これらのモデルは、画像編集、画像合成、画像変換などによく使われる。画像生成モデルは、[LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst)のような大規模な画像データセットで学習されることが多く、新しい画像を生成したり、インペインティング、超解像、カラー化の技術を使って既存の画像を編集したりするのに使われます。例えば、[DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst)や[安定拡散モデル](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst)などがあります。

![画像生成](../../images/Image.png?WT.mc_id=academic-105485-koreyst)

テキスト・コード生成モデルは、テキストやコードを生成するモデルである。これらのモデルは、テキストの要約、翻訳、質問応答などによく使用される。テキスト生成モデルは、[BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst)のような大規模なテキストデータセットで学習されることが多く、新しいテキストを生成したり、質問に答えたりするのに使われます。CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst)のようなコード生成モデルは、多くの場合、GitHubのようなコードの大規模なデータセットで学習され、新しいコードを生成したり、既存のコードのバグを修正したりするのに使われる。

 ![テキストとコード生成](../../images/Text.png?WT.mc_id=academic-105485-koreyst)

### エンコーダー・デコーダー対デコーダー・オンリー

LLMのさまざまなタイプのアーキテクチャについて話すために、例え話を使おう。

あなたの上司が学生に小テストを作成する仕事を与えたとします。 あなたには2人の同僚がいます。1人はコンテンツの作成を監督し、もう1人はそのレビューを監督します。

コンテンツ作成者はデコーダーのみのモデルのようなもので、トピックを見て、あなたがすでに書いたものを確認し、それに基づいてコースを書くことができる。彼らは魅力的で有益なコンテンツを書くのは得意ですが、トピックや学習目標を理解するのは苦手です。デコーダーの例としては、GPT-3などのGPTファミリーのモデルがある。

レビュアーはエンコーダーのみのモデルのようなもので、書かれたコースと答えを見て、それらの間のリレーションシップに気づき、コンテクストを理解しますが、コンテンツを生成することは得意ではありません。エンコーダのみのモデルの例としては、BERTが挙げられる。

小テストを作成し、レビューすることができる人がいることを想像してください、これはエンコーダ-デコーダモデルです。BARTやT5がその例である。

### サービス対モデル

では、サービスとモデルの違いについて話しましょう。サービスとは、クラウドサービスプロバイダーによって提供される製品で、多くの場合、モデル、データ、その他のコンポーネントの組み合わせです。モデルはサービスの核となるコンポーネントで、LLMのような基盤モデルであることが多い。

サービスは多くの場合、実運用に最適化されており、グラフィカル・ユーザー・インターフェースを介して、モデルよりも使いやすくなっている。しかし、サービスは常に無料で利用できるわけではなく、サービス所有者の設備やリソースを活用し、費用を最適化し、簡単に拡張できる代わりに、利用にはサブスクリプションや支払いが必要になる場合がある。サービスの一例として、[Azure OpenAIサービス](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst)がある。これは従量課金の料金プランを提供するもので、ユーザーはサービスの利用量に比例して課金される。また、Azure OpenAIサービスは、モデル機能の上にエンタープライズグレードのセキュリティと責任あるAIフレームワークを提供する。

モデルは、パラメータや重みなどを持つニューラルネットワークに過ぎない。しかし、企業がローカルで実行できるようにするには、機器を購入し、スケールするための構造を構築し、ライセンスを購入するか、オープンソースのモデルを使用する必要がある。LLaMAのようなモデルを利用するには、モデルを実行するための計算能力が必要である。

## Azureでのパフォーマンスを理解するために、さまざまなモデルをテストし、反復する方法

私たちのチームが現在のLLMの状況を調査し、シナリオに適した候補をいくつか特定したら、次のステップは、データとワークロードでそれらをテストすることです。これは実験とメジャーによる反復プロセスです。
前の段落で述べたモデル（OpenAIモデル、Llama2のようなオープンソースモデル、Hugging Faceトランスフォーマー）のほとんどは、[Azure Machine Learning studio](https://ml.azure.com/?WT.mc_id=academic-105485-koreyst)の[Foundation Models](https://learn.microsoft.com/azure/machine-learning/concept-foundation-models?WT.mc_id=academic-105485-koreyst)カタログで利用できる。

[Azure Machine Learning](https://azure.microsoft.com/products/machine-learning/?WT.mc_id=academic-105485-koreyst)は、データサイエンティストやMLエンジニアのために設計されたクラウドサービスで、MLのライフサイクル全体（トレーニング、テスト、デプロイ、MLOpsの処理）を単一のプラットフォームで管理することができる。Machine Learning studioは、このサービスにグラフィカル・ユーザー・インターフェースを提供し、ユーザーは以下のことができる：

- タスク、ライセンス、または名前でフィルタリングして、カタログから関心のあるファウンデーションモデルを検索します。まだカタログに含まれていない新しいモデルをインポートすることも可能です。
- 詳細な説明やコードサンプルを含むモデルカードを確認し、サンプル推論ウィジェットで結果をテストするためのサンプルプロンプトを提供してテストします。

![モデルカード](../../images/Llama1.png?WT.mc_id=academic-105485-koreyst)

- 特定のワークロードと入力で提供された特定のデータセットについて、客観的な評価メトリクスでモデルのパフォーマンスを評価します。

![モデル評価](../../images/Llama2.png?WT.mc_id=academic-105485-koreyst)

- Azure Machine Learning の実験と追跡機能を活用して、特定のワークロードでモデルのパフォーマンスを向上させるために、カスタムトレーニングデータでモデルを微調整します。

![モデルの微調整](../../images/Llama3.png?WT.mc_id=academic-105485-koreyst)

- 事前に訓練されたオリジナルのモデル、または微調整されたモデルをリモートのリアルタイム推論またはバッチエンドポイントにデプロイし、アプリケーションがそれを利用できるようにします。

![モデルのデプロイ](../../images/Llama4.png?WT.mc_id=academic-105485-koreyst)

## LLMの結果を改善する

我々はスタートアップチームと様々な種類のLLMと、様々なモデルを比較し、テストデータで評価し、パフォーマンスを向上させ、推論エンドポイントにデプロイすることを可能にするクラウドプラットフォーム（Azure Machine Learning）を検討してきた。

しかし、どのような場合に、事前に訓練されたモデルを使用するのではなく、モデルの微調整を検討しなければならないのでしょうか？特定のワークロードでモデルのパフォーマンスを向上させる他のアプローチはあるのだろうか？

LLMから必要な結果を得るために、ビジネスにはいくつかのアプローチがあります。

複雑さ、コスト、品質のレベルが異なるLLMを実運用に導入することができます。以下は、いくつかの異なるアプローチである：

- **コンテキスト**でエンジニアリングを促進する。このアイデアは、必要な回答を確実に得るために、プロンプトを出すときに十分なコンテキストを提供することである。

- **検索拡張生成、RAG**。例えば、データがデータベースやウェブエンドポイントに存在する場合、プロンプトを出すときにこのデータ、またはそのサブセットが含まれるように、関連するデータをフェッチし、それをユーザーのプロンプトの一部にすることができます。

- **ファインチューニングされたモデル**。ここでは、独自のデータでモデルをさらにトレーニングし、モデルをより正確でニーズに対応したものにしますが、コストがかかる場合があります。

![LLMsのデプロイメント](../../images/Deploy.png?WT.mc_id=academic-105485-koreyst)

画像ソース [企業がLLMを導入する4つの方法｜Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### コンテキストを使ったプロンプトエンジニアリング

事前に訓練されたLLMは、文の完成や質問のような短いプロンプトを呼び出しても、一般化された自然言語タスクでは非常にうまく機能する。

しかし、ユーザーが詳細な要求や例（コンテキスト）を使ってクエリを構成すればするほど、より正確でユーザーの期待に最も近い回答が得られる。この場合、プロンプトに1つの例しか含まれていない場合は「ワンショット」学習、複数の例が含まれている場合は「数ショット学習」と呼ぶ。
文脈を考慮したプロンプトエンジニアリングは、最も費用対効果の高いアプローチである。

### 検索拡張生成（RAG）

LLMには、答えを生成するために、トレーニング中に使われたデータしか使えないという制限がある。つまり、LLMは訓練プロセスの後に起こった事実については何も知らないし、非公開情報（企業データなど）にもアクセスできない。
これは、プロンプトの長さの制限を考慮しながら、プロンプトをドキュメントのチャンクの形で外部データで補強する技術であるRAGによって克服することができる。これはベクターデータベースツール（[Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)など）によってサポートされ、様々な事前定義されたデータソースから有用なチャンクを取得し、プロンプトコンテキストに追加する。

このテクニックは、ビジネスがLLMを微調整するのに十分なデータ、十分な時間、またはリソースを持っていないが、それでも特定のワークロードのパフォーマンスを向上させ、捏造、すなわち現実の神秘化や有害なコンテンツのリスクを低減したい場合に非常に便利です。 

### ファインチューニング・モデル

ファインチューニングとは、モデルを下流のタスクに「適応」させたり、特定の問題を解決したりするために、転移学習を活用するプロセスである。数ショット学習やRAGとは異なり、重みとバイアスを更新した新しいモデルが生成される。これは、単一の入力（プロンプト）とそれに関連する出力（完了）からなる訓練例のセットを必要とする。
これは次のような場合に好ましいアプローチである：

- **微調整されたモデルの使用**。ビジネスでは、高性能モデルではなく、（エンベッディング・モデルのような）微調整された性能の低いモデルを使用したい。

- **レイテンシーの考慮**。特定のユースケースにとってレイテンシーは重要であるため、非常に長いプロンプトを使用することはできないか、モデルから学習すべき例の数がプロンプトの長さの制限に合わない。

- **最新の状態に保つこと**。ビジネスには、多くの高品質データとグランドトゥルースラベルがあり、このデータを長期間にわたって最新の状態に維持するために必要なリソースがあります。

### 学習済みモデル

LLMをゼロからトレーニングすることは、間違いなく最も難しく、最も複雑なアプローチである。このオプションは、ビジネスがドメイン固有のユースケースを持ち、ドメイン中心のデータが大量にあるシナリオでのみ考慮されるべきである。

## 知識チェック

LLMの完了結果を改善するために、どのようなアプローチが考えられるか？

1. コンテキストを使ったプロンプトエンジニアリング
1. RAG
1. モデルの微調整

A:3、もし時間とリソースがあり、質の高いデータがあるのであれば、ファインチューニングの方が最新の状態を維持するためには良い選択肢です。しかし、もしあなたが物事を改善しようと考えていて、時間がないのであれば、まずRAGを検討する価値がある。

## 🚀チャレンジ

[RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst)をどのようにビジネスに活用できるか、詳しくはこちらをお読みください。

## 素晴らしい仕事、学習を続けよう

このレッスンを終えたら、[Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst)をチェックして、Generative AIの知識のレベルアップを続けましょう！

レッスン3では、[責任を持ってジェネレーティブAIで構築する](../../../03-using-generative-ai-responsibly/README.md)方法を見ていきます！
