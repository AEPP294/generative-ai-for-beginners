# プロンプト エンジニアリングの基礎

[![プロンプト工学基礎](../../images/04-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://youtu.be/r2ItK3UMVTk?WT.mc_id=academic-105485-koreyst)


LLMへのプロンプトをどのように書くかは重要であり、注意深く作られたプロンプトは、そうでないものよりも良い結果を得ることができる。しかし、プロンプト、プロンプト・エンジニアリングという概念は一体何なのだろうか？このような疑問に対する答えが、この章と次の章である。

生成AIは、ユーザーの要求に応じて新しいコンテンツ（テキスト、画像、音声、コードなど）を生成することができる。これは、OpenAIのGPT（"Generative Pre-trained Transformer"）シリーズのような、自然言語やコードを使用するために訓練された大規模言語モデル（LLM）を使用して実現されます。

ユーザーは、技術的な専門知識やトレーニングを必要とせず、チャットのような馴染みのあるパラダイムを使用して、これらのモデルと対話することができます。このモデルは「プロンプト・ベース」であり、ユーザーはテキスト入力（プロンプト）を送信し、AIの応答（完了）が返ってくる。その後、ユーザーは「AIとチャット」することができ、何度も会話を繰り返しながら、返答が自分の期待に沿うまでプロンプトを改良していく。

「プロンプト」は今や生成AIアプリの主要なプログラミング・インターフェースとなり、モデルに何をすべきかを指示し、返される応答の品質に影響を与える。「プロンプトエンジニアリング」は、プロンプトの設計と最適化に焦点を当てた急成長中の研究分野であり、一貫性のある質の高い応答を大規模に提供する。

## 学習目標

このレッスンでは、プロンプトエンジニアリングとは何か、なぜプロンプトエンジニアリングが重要なのか、そして与えられたモデルやアプリケーションの目的に対してより効果的なプロンプトを作成する方法について学びます。プロンプトエンジニアリングのコアコンセプトとベストプラクティスを理解し、これらのコンセプトが実際の例に適用されるのを見ることができるインタラクティブなJupyter Notebooksの「サンドボックス」環境について学びます。

このレッスンの終わりには、以下のことができるようになります：

1. プロンプトエンジニアリングとは何か、なぜ重要なのかを説明できる。
2. プロンプトの構成要素とその使用方法について説明する。
3. プロンプトエンジニアリングのベストプラクティスとテクニックを学ぶ。
4. OpenAIのエンドポイントを使って、学んだテクニックを実例に適用する。

## 学習サンドボックス

プロンプトエンジニアリングは現在のところ、科学というより芸術です。プロンプトエンジニアリングの直感を向上させる最良の方法は、もっと練習し、アプリケーションドメインの専門知識と推奨されるテクニックやモデル固有の最適化を組み合わせた試行錯誤のアプローチを採用することです。

このレッスンに付属するJupyter Notebookは、学んだことを試すことができる_サンドボックス_環境を提供します。練習問題を実行するには、以下のものが必要です：

1. OpenAI API キー - デプロイされた LLM のサービスエンドポイント。

2. Python ランタイム - ノートブックを実行することができます。

私たちはこのリポジトリに、Python 3ランタイムが付属する_dev container_を組み込みました。GitHub CodespacesまたはローカルのDocker Desktopでリポジトリを開くだけで、自動的にランタイムが有効になります。それからノートブックを開き、Python 3.xカーネルを選択して、ノートブックの実行を準備します。

デフォルトのノートブックは、OpenAI API Keyで使用するように設定されています。フォルダーのルートにある `.env.copy` ファイルを `.env` にコピーし、`OPENAI_API_KEY=` 行をあなたの API キーで更新するだけです。

このノートブックには _starter_ 練習問題が付属していますが、独自の _Markdown_ (説明) や _Code_ (プロンプトのリクエスト) セクションを追加して、より多くの例やアイデアを試してみてください。

## スタートアップ

では、このトピックが私たちのスタートアップのミッションである[教育にAIイノベーションをもたらす](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst)にどのように関係しているのかについてお話ししましょう。そこで、私たちのアプリケーションのさまざまなユーザーがどのようにプロンプトを「デザイン」するかを考えてみましょう：

- **管理者**は、カリキュラムのデータを分析し、カバー範囲のギャップを特定するようAIに求めるかもしれない。AIは結果を要約したり、コードで可視化することができます。
- **教育者**はAIに、対象者とトピックのためのレッスンプランを生成するよう求めるかもしれません。AIは、指定されたフォーマットでパーソナライズされたプランを構築することができます。
- **学生**は、AIに難しい科目の個人指導を依頼するかもしれません。AIは、生徒のレベルに合わせた授業、ヒント、例題で生徒を導くことができる。

これは氷山の一角です。[Prompts For Education](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst)-教育の専門家によってキュレーションされたオープンソースのプロンプト・ライブラリ-をチェックすれば、より幅広い可能性を感じることができる！これらのプロンプトのいくつかをサンドボックスで動かしてみたり、OpenAI Playgroundを使って何が起こるか見てみよう！！

<!--
レッスンのテンプレート
このユニットはコアコンセプト#1をカバーする必要があります。
例や参考文献を使ってコンセプトを強化しましょう。

コンセプト #1：
プロンプトエンジニアリング。
それを定義し、なぜそれが必要なのかを説明する。
-->

## プロンプトエンジニアリングとは何か？

このレッスンでは、**プロンプトエンジニアリング** を、与えられたアプリケーションの目的とモデルに対して、一貫性のある質の高い回答(完了)を提供するために、テキスト入力(プロンプト)を設計し最適化するプロセスと定義することから始めました。これは2段階のプロセスと考えることができます：

- 与えられたモデルと目的に対する最初のプロンプトの設計
- プロンプトを反復的に洗練させ、回答の質を向上させる

これは必然的に試行錯誤のプロセスであり、最適な結果を得るためにはユーザーの直感と努力が必要となる。では、なぜそれが重要なのか？その問いに答えるには、まず3つの概念を理解する必要がある：

- トークナイゼーション = モデルがプロンプトをどのように「認識」するか
- 基本LLM_ = 基本モデルがプロンプトを「処理」する方法
- インストラクション・チューンドLLMs = モデルが "タスク "を見る方法

### トークナイゼーション

LLMはプロンプトを「トークンのシーケンス」として認識し、異なるモデル（ま たはモデルのバージョン）は同じプロンプトを異なる方法でトークン化できる。LLMは(生のテキストではなく)トークンに対して学習されるため、プロンプトがトークン化される方法は生成される応答の品質に直接影響する。

トークナイゼーションがどのように機能するか直感的に理解するには、以下の[OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst)のようなツールを試してみてください。プロンプトをコピーして、空白文字や句読点がどのように扱われるかに注意しながら、それがどのようにトークンに変換されるかを見てください。この例は古いLLM(GPT-3)を使っていることに注意してください。

![トークナイゼーション](../../images/04-tokenizer-example.png?WT.mc_id=academic-105485-koreyst)

### コンセプト 基礎モデル

プロンプトがトークン化されると、["ベースLLM"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst)(またはファウンデーションモデル)の主な機能は、そのシーケンスのトークンを予測することである。LLMは膨大なテキストデータセットで訓練されているため、トークン間の統計的なリレーションシップに精通しており、ある程度自信を持って予測することができる。LLMはプロンプトやトークンに含まれる単語の「意味」を理解しているわけではなく、次の予測で「完了」できるパターンを見ているだけである。彼らは、ユーザーの介入や事前に設定された条件によって終了するまで、シーケンスを予測し続けることができる。

プロンプトベースの補完がどのように機能するか見てみましょうか？上記のプロンプトをAzure OpenAI Studio [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst)にデフォルト設定で入力します。システムはプロンプトを情報の要求として扱うように設定されているので、このコンテキストを満たす補完が表示されるはずです。

しかし、ユーザーが何らかの基準やタスクの目的を満たす特定のものを見たいとしたらどうでしょうか？そこで、_instruction-tuned_ LLMが登場します。

![ベースLLMチャット完了](../../images/04-playground-chat-base.png?WT.mc_id=academic-105485-koreyst)

### コンセプト 命令チューニングLLM

[Instruction Tuned LLM](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst)は、基礎モデルから始まり、明確な指示を含むことができる例や入出力のペア(例えば、複数ターンの「メッセージ」)を使ってそれを微調整します-そして、AIはその指示に従おうとします。

これは、人間のフィードバックによる強化学習（RLHF）のようなテクニックを使用し、モデルを「指示に従う」ように訓練し、「フィードバックから学習する」ことで、より実用的なアプリケーションに適した、ユーザーの目的に関連した応答を生成することができる。

試してみましょう。上のプロンプトをもう一度見ますが、今度は「システムメッセージ」を変更して、コンテキストとして次の指示を提供します：

> 2年生の生徒のために提供されたコンテンツを要約してください。結果は3～5個の箇条書きで1段落にまとめなさい。

結果が、望ましい目標と形式を反映するように調整されているのがわかるでしょうか。教育者はこの回答を、そのクラスのスライドに直接使うことができます。

![指示調整済みLLMチャット完了](../../images/04-playground-chat-instructions.png?WT.mc_id=academic-105485-koreyst)

## なぜプロンプト・エンジニアリングが必要なのか?

プロンプトがLLMによってどのように処理されるかがわかったところで、プロンプト・エンジニアリングがなぜ必要なのかについて話そう。その答えは、現在のLLMには、プロンプトの構築や最適化に力を入れないと、「信頼性が高く一貫性のある完走」を達成するのが難しくなるような課題がいくつもあるという事実にある。例えば

1. **同じプロンプト**でも、モデルやモデルのバージョンが異なれば、異なる回答が得られる可能性が高い。同じプロンプトであっても、モデルやモデルのバージョンが異なれば、異なる結果が得られる可能性がある。プロンプトエンジニアリングのテクニックは、より良いガードレールを提供することで、このようなばらつきを最小限に抑えるのに役立ちます。

1. **モデルは、「大きいが細かい」**データセットで事前にトレーニングされているため、そのトレーニング範囲外の概念に関する知識が不足しています。その結果、不正確な、想像上の、あるいは既知の事実と直接矛盾する回答をすることがあります。 プロンプトエンジニアリングの技術は、AIに引用や推論を求めるなどして、ユーザーがそのような捏造を特定し、軽減するのに役立ちます。

1. **新しいモデルやモデルの世代**は、より豊富な機能を持ちますが、ユニークな癖や、コストや複雑さのトレードオフももたらします。プロンプトエンジニアリングは、違いを抽象化し、スケーラブルでシームレスな方法でモデル固有の要件に適応するベストプラクティスとワークフローを開発するのに役立ちます。

これをOpenAIやAzure OpenAI Playgroundで実際に見てみましょう：

- 同じプロンプトを異なるLLMデプロイメント（例：OpenAI、Azure OpenAI、Hugging Face）で使ってみてください。
- 同じ LLM デプロイメント（例：Azure OpenAI プレイグラウンド）で同じプロンプトを繰り返し使用します - これらのバリエーションはどのように違いましたか？

### ファブリケーションの例

このコースでは、LLMがトレーニングの制限や他の制約のために時々事実と異なる情報を生成する現象について言及するために、**"捏造 "**という用語を使います。また、一般的な記事や研究論文で、この現象を「幻覚」と呼ぶのを聞いたことがあるかもしれません。しかし、私たちは「捏造」_という言葉を使うことを強く推奨します。そうすることで、機械主導の結果に人間のような特徴を帰属させることで、その行動を誤って擬人化してしまうことがなくなるからです。これはまた、用語の観点から[Responsible AI guidelines](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst)を強化し、文脈によっては攻撃的または非包括的とみなされる可能性のある用語を削除します。

捏造がどのように機能するかの感覚をつかみたいですか？存在しないトピックのコンテンツを生成するようAIに指示するプロンプトを考えてみよう（学習データセットにないことを確認するため）。例えば、次のようなプロンプトを試してみた：
> 2076年の火星戦争に関するレッスンプランを生成してください。

ウェブで検索してみると、火星戦争に関する架空の記述（テレビシリーズや本など）はあったが、2076年のものはなかった。常識的に考えて、2076年は「未来」であり、現実の出来事とは考えられない。

では、このプロンプトを異なるLLMプロバイダーで実行するとどうなるか？

> レスポンス1 OpenAI Playground (GPT-35)

![応答1](../../images/04-fabrication-oai.png?WT.mc_id=academic-105485-koreyst)。

> レスポンス 2**： Azure OpenAI プレイグラウンド (GPT-35)

![レスポンス 2](../../images/04-fabrication-aoai.png?WT.mc_id=academic-105485-koreyst)。

> 反応3**: : 抱きつき顔チャット遊び場 (LLama-2)

![レスポンス3](../../images/04-fabrication-huggingchat.png?WT.mc_id=academic-105485-koreyst)

予想通り、各モデル（またはモデルのバージョン）は、確率的な挙動とモデル能力のばらつきのおかげで、わずかに異なる反応を示している。たとえば、1つのモデルは8年生をターゲットにしていますが、もう1つのモデルは高校生を想定しています。しかし、3つのモデルすべてが、何も知らないユーザーにその出来事が現実であると確信させるような応答を生成した。

メタプロンプトや温度設定のようなプロンプトエンジニアリングの技術は、モデルの捏造をある程度減らすことができる。新しいプロンプトエンジニアリングアーキテクチャーは、新しいツールや技術をプロンプトフローにシームレスに組み込むことで、これらの影響を緩和または軽減することができる。

## ケーススタディ GitHub Copilot

プロンプトエンジニアリングが実際のソリューションでどのように使われているかを、あるケーススタディから感じ取って、このセクションを締めくくろう： [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst)です。

GitHub Copilotは、あなたの「AIペアプログラマー」です。テキストプロンプトをコード補完に変換し、シームレスなユーザーエクスペリエンスのために開発環境（Visual Studio Codeなど）に統合されています。以下の一連のブログで文書化されているように、初期のバージョンはOpenAI Codexモデルに基づいていました - エンジニアはすぐに、コードの品質を向上させるために、モデルを微調整し、より良いプロンプトエンジニアリング技術を開発する必要性に気づきました。7月、彼らは[Codexを超える改善されたAIモデルをデビューさせた](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)。

彼らの学習の旅をたどるために、投稿を順番に読んでください。

- 2023年5月**日｜[GitHub Copilotがあなたのコードをより理解するようになる](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- 2023年5月**日｜[Inside GitHub: Working with the LLMs behind GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst).
- 2023年6月**日｜[GitHub Copilotのプロンプトの書き方](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst).
- 2023年7月**日｜[. GitHub CopilotはAIモデルを改良してCodexを超える](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- 2023年7月**日｜[A Developer's Guide to Prompt Engineering and LLMs](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- 2023年9月**日｜[How to build an enterprise LLM app: Lessons from GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

[エンジニアリングブログ](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst)には、これらのモデルやテクニックが実際のアプリケーションにどのように適用されているかを示す[このブログ](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst)のような投稿もあります。

---

<!--
レッスンのテンプレート
このユニットでは、コアコンセプト#2をカバーする必要があります。
例や参考文献を用いてコンセプトを強化する。

コンセプト#2：
プロンプトのデザイン。
例を用いて説明する。
-->

## プロンプトの構成

プロンプトエンジニアリングがなぜ重要であるかを見てきました。次に、プロンプトがどのように構成されるかを理解し、より効果的なプロンプトデザインのためのさまざまなテクニックを評価できるようにしましょう。

### 基本的なプロンプト

基本的なプロンプトから始めましょう。他のコンテキストがない状態でモデルに送信されるテキスト入力です。例えば、OpenAIの[Completion API](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst)にアメリカ国歌の最初の数単語を送ると、即座に次の数行のレスポンスが補完され、基本的な予測動作が示されます。

| プロンプト(入力) | 補完(出力)
|:---|:---|
| Oh say can you see | アメリカの国歌である「星条旗」の歌詞を始めているようですね。歌詞の全文は |

### 複雑なプロンプト

では、この基本的なプロンプトにコンテキストと指示を追加してみましょう。[チャット補完API](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst)では、_messages_のコレクションとして複雑なプロンプトを作成することができます：

- ユーザーの入力とアシスタントの応答を反映する入出力ペア。
- アシスタントの動作やパーソナリティのコンテキストを設定するシステムメッセージ。

リクエストは以下のような形になり、_tokenization_はコンテキストと会話から関連する情報を効果的に取り込みます。さて、システムのコンテキストを変更することは、提供されたユーザー入力と同様に、完了の品質に影響を与えることができます。

```python
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```

### 命令プロンプト

上記の例では、ユーザープロンプトは情報の要求と解釈できる単純なテキストクエリでした。命令プロンプトでは、そのテキストを使用してタスクをより詳細に指定し、AIにより良いガイダンスを提供することができます。以下に例を示す：

| プロンプト（入力）｜完了（出力）｜命令タイプ
|:---|:---|:---|
| 南北戦争についての説明を書きなさい。
|南北戦争についての説明を書きなさい。主要な日付と出来事を示し、その重要性を説明しなさい。
|南北戦争について1段落で説明しなさい。重要な日付とその意味を箇条書きで3つ述べなさい。主要な歴史上の人物とその貢献について、さらに3つの箇条書きを書きなさい。JSONファイルとして出力を返す| _ファイルにコピーペーストして必要に応じて検証できるJSONとしてフォーマットされたテキストボックスに、より広範な詳細を返す_|複雑。書式付き。|

## 主な内容

上記の例では、プロンプトはまだかなりオープンエンドで、LLMが事前に訓練されたデータセットのどの部分に関連するかを決めることができました。primary content_デザインパターンでは、入力テキストは2つの部分に分けられる：

- 指示（行動）
- 関連するコンテンツ（アクションに影響を与える）

以下は、「これを2つのセンテンスに要約せよ」という指示の例である。

| プロンプト（入力）｜完了（出力
|:---|:---|
| 木星は太陽から5番目の惑星で、太陽系最大の惑星である。質量は太陽の1,000分の1だが、太陽系の他の惑星を合わせると2.5倍もある巨大なガス惑星である。木星は、夜空に肉眼で見える最も明るい天体のひとつであり、有史以前から古代文明に知られていた。地球から見ると、木星はその反射光が目に見える影を落とすほど明るいことがあり[20]、月と金星に次いで夜空で平均して3番目に明るい自然天体である。<br/> **これを2つの短い文章にまとめる**｜太陽から5番目の惑星である木星は、太陽系で最も大きく、夜空で最も明るい天体の1つとして知られている。ローマ神話の神ジュピターにちなんで名づけられた木星は、太陽系の他の惑星を合わせた質量の2.5倍もある巨大なガス惑星である。|

プライマリーコンテンツセグメントは、より効果的なインストラクションを推進するために、さまざまな方法で使用することができます：

- **例** - 明示的な指示で何をすべきかをモデルに教える代わりに、何をすべきかの例を与え、パターンを推測させる。
- **手がかり** - 指示の後に「手がかり」を与えることで、完了を促し、モデルをより適切な回答へと導きます。
- テンプレート** - これは、特定のユースケースのためにデータでカスタマイズすることができるプレースホルダ（変数）を持つプロンプトのための繰り返し可能な「レシピ」です。

これらを実際に試してみましょう。

### 例の使用

これは、主要なコンテンツを使用して、与えられた命令に対して望ましい出力の例をいくつか「モデルに与え」、望ましい出力のパターンを推測させるアプローチです。提供される例の数に基づいて、ゼロショットプロンプト、ワンショットプロンプト、スモールショットプロンプトなどがあります。

プロンプトは3つの要素から構成される：

- タスクの説明
- 希望する出力のいくつかの例
- 新しい例の開始（これが暗黙のタスク記述になる）


| 学習タイプ｜プロンプト（入力）｜完了（出力
|:---|:---|:---|
| ゼロショット｜"The Sun is Shining". スペイン語に翻訳する | "El Sol está brillando".|.
| スペイン語に翻訳｜ワンショット｜「太陽は輝いている」⇒「El Sol está brillando. <br>「今日は寒く風の強い日です」⇒｜"Es un día frío y ventoso". |
<br/> 「選手が走塁した」⇒「野球」<br/> 「選手がエースを打った」⇒「テニス」<br/> 「選手が6番を打った」⇒「クリケット」<br/> 「選手がスラムダンクを決めた」⇒「バスケットボール」</br
| | | |


ゼロショットプロンプトでは明示的な指示（「スペイン語に翻訳してください」）を与えなければならなかったが、ワンショットプロンプトの例では推測されることに注意。数ショットの例では、より多くの例を追加することで、指示を追加しなくてもモデルがより正確な推論を行えることを示している。

### プロンプトの手がかり

一次コンテンツを使うもう一つのテクニックは、例ではなく「手がかり」を提供することです。この場合、望ましい応答形式を反映したスニペットでモデルをスタートさせることで、 正しい方向へ促すのです。するとモデルは、その調子で続けるように「合図を送る」。


| キューの数｜プロンプト(入力)｜完了(出力)
|:---|:---|:---|
| 0｜木星は太陽から5番目の惑星で、太陽系最大の惑星である。質量は太陽の1,000分の1だが、太陽系の他の惑星を合わせると2.5倍もある巨大なガス惑星である。木星は夜空に肉眼で見える最も明るい天体の一つであり、記録に残る以前から古代文明に知られていた。 <br/>**まとめ**｜木星は太陽系最大の惑星であり、太陽から5番目の惑星である。質量は太陽の1000分の1だが、他のすべての惑星を合わせたよりも重い。古代文明は長い間、木星について知っており、夜空に簡単に見える。
| 1｜木星は太陽から5番目の惑星で、太陽系最大の惑星である。質量は太陽の1,000分の1だが、太陽系の他の惑星を合わせると2.5倍もある巨大なガス惑星だ。木星は夜空に肉眼で見える最も明るい天体の一つであり、記録に残る以前から古代文明に知られていた。  質量は太陽の1000分の1だが、他の惑星を合わせると2.5倍になる。肉眼で容易に見ることができ、古くから知られている。|
| 2｜木星は太陽から5番目の惑星で、太陽系最大の惑星である。質量は太陽の1,000分の1だが、太陽系の他の惑星を合わせると2.5倍もある巨大なガス惑星である。木星は夜空に肉眼で見える最も明るい天体の一つであり、記録に残る以前から古代文明に知られていた。  <br/>1.木星は太陽から5番目の惑星であり、太陽系最大の惑星である。<br/> 2.太陽の1000分の1の質量を持つガス惑星である。 <br/> 3.木星は古代から肉眼で見ることができた。|
| | | |


### プロンプトテンプレート

プロンプトテンプレートとは、必要に応じて保存して再利用することができる、プロンプトのための「あらかじめ定義されたレシピ」であり、規模に応じてより一貫性のあるユーザーエクスペリエンスを促進する。最も単純な形では、[OpenAIからのもの](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst)のようなプロンプトの例を集めたもので、インタラクティブなプロンプトコンポーネント(ユーザーとシステムのメッセージ)とAPI駆動型のリクエストフォーマットの両方を提供し、再利用をサポートする。

LangChainのこの例](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/?WT.mc_id=academic-105485-koreyst)のような、より複雑な形式では、プロンプトを動的に生成するために、さまざまなソース(ユーザー入力、システムコンテキスト、外部データソースなど)からのデータで置き換えることができる_placeholders_が含まれています。これにより、再利用可能なプロンプトのライブラリを作成することができ、これを使用して**プログラム的に**一貫したユーザーエクスペリエンスを大規模に推進することができます。

最後に、テンプレートの本当の価値は、垂直アプリケーションドメイン用のプロンプトライブラリを作成して公開できることにあります。Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst)リポジトリはこのアプローチの素晴らしい例であり、授業計画、カリキュラム設計、生徒指導などの主要な目的に重点を置いた教育分野のプロンプトライブラリをキュレーションしています。

##サポートコンテンツ

プロンプトの作成について、インストラクション（タスク）とターゲット（プライマリコンテンツ）があると考えるならば、セカンダリコンテンツとは、**何らかの方法で**アウトプットに影響を与えるために提供する追加的なコンテキストのようなものである。これは、チューニングパラメータ、フォーマット命令、トピック分類などであり、モデルがユーザーの目的や期待に合うようにレスポンスを調整するのに役立ちます。

例えば カリキュラムで利用可能なすべてのコースに関する広範なメタデータ（名前、説明、レベル、メタデータタグ、インストラクターなど）を持つコースカタログがあるとします：

- 2023年秋のコースカタログを要約する」命令を定義することができます。
- 主コンテンツを使用して、必要な出力の例をいくつか提供することができます。
- 二次コンテンツを使用して、関心のある上位5つの「タグ」を識別します。

しかし、結果が複数のタグを持つ場合、二次コンテンツで特定された5つのタグに優先順位をつけることができます。

---

<!--
レッスンのテンプレート
このユニットはコアコンセプト#1をカバーする必要があります。
例や参考文献を用いてコンセプトを強化する。

コンセプト#3：
プロンプトエンジニアリングのテクニック
プロンプトエンジニアリングの基本的なテクニックにはどのようなものがあるか。
練習問題を用いて説明しなさい。
-->

## プロンプトのベストプラクティス

プロンプトがどのように「構成」されるかがわかったので、ベストプラクティスを反映させるためにプロンプトをどのように「設計」するかを考え始めましょう。正しいマインドセットを持つことと、正しいテクニックを適用することです。

### プロンプト・エンジニアリングのマインドセット

プロンプト・エンジニアリングは試行錯誤のプロセスなので、3つの大まかな指針を念頭に置いてください：

1. **レスポンスの精度と関連性は、そのアプリケーションやユーザーが使用する「ドメイン」の機能です。直感とドメインの専門知識を適用して、テクニックをさらに**カスタマイズする。例えば、システムプロンプトでドメイン固有のパーソナリティを定義したり、ユーザープ ロンプトでドメイン固有のテンプレートを使用する。ドメイン固有のコンテキストを反映した二次的なコンテンツを提供したり、_domain-specific cues and examples_を使用してモデルを馴染みのある使用パターンに導く。

2. **モデルの理解は重要です。しかし、モデルの実装は、使用するトレーニングデータセット（事前にトレーニングされた知識）、提供する機能（APIやSDK経由など）、最適化されるコンテンツのタイプ（コード対画像対テキストなど）という点でも異なります。使用しているモデルの長所と限界を理解し、その知識を使用して、タスクに優先順位をつけたり、モデルの能力に最適化されたテンプレートを構築します。

3. **モデルは急速に進化しており、プロンプトエンジニアリングの技術も進化しています。ドメインの専門家であるあなたには、より広範なコミュニティには当てはまらないかもしれない、他のコンテキストや基準があるかもしれません。プロンプトエンジニアリングツールとテクニックを使用してプロンプトの作成を「ジャンプスタート」し、自分の直感と専門知識を使用して結果を反復し検証する。あなたの洞察を記録し、他の人が新しいベースラインとして使用できる **知識ベース** (例: プロンプトライブラリ) を作成する。

## ベストプラクティス

では、[Open AI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst)と[Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst)の実践者が推奨する一般的なベストプラクティスを見てみよう。

|何を|なぜ|?

| 最新モデルを評価する。| 新しい世代のモデルは、機能や品質が向上している可能性が高いが、コストが高くなる可能性もある。影響を評価し、移行を決定する。|
| 指示とコンテキストの分離｜モデル／プロバイダが、指示、主コンテンツ、副コンテンツをより明確に区別するための「区切り記号」を定義しているかどうかをチェックする。これはモデルがトークンにより正確に重みを割り当てるのに役立つ。|
|具体的かつ明確に｜望ましい文脈、結果、長さ、形式、スタイルなどについて、より詳細に説明しましょう。これにより、回答の質と一貫性の両方が向上します。再利用可能なテンプレートにレシピを取り込む。|
|説明的であること、例を使うこと、モデルは "show and tell "アプローチによりよく反応するかもしれません。ゼロショット（zero-shot）アプローチから始め、指示（しかし例はない）を与える。類推を使う。
|完了をジャンプスタートさせる合図を使う|応答の出発点として使えるような、先行する言葉やフレーズを与えることで、望ましい結果へと誘導する。
|ダブルダウン｜時には、モデルに対して繰り返し話す必要があるかもしれません。主な内容の前後に指示を与える、指示と合図を使い分ける、など。何が効果的か、繰り返し検証してください。
| 順序は重要｜モデルに情報を提示する順序は、たとえ学習例であっても、再帰性バイアスのおかげでアウトプットに影響を与えるかもしれません。さまざまなオプションを試して、何が一番うまくいくかを確認しましょう。
|モデルに "out "を与える｜何らかの理由でタスクを完了できない場合、モデルに_fallback_完了応答を与えます。こうすることで、モデルが誤った回答や捏造した回答をする可能性を減らすことができます。|
| | |

どのようなベストプラクティスにも言えることですが、モデル、タスク、そして領域によって「あなたのやり方は異なる」ことを覚えておいてください。これらを出発点として、あなたにとって最適なものを見つけるために繰り返してください。プロセスのスケーラビリティと応答品質に焦点を当てながら、新しいモデルやツールが利用可能になるにつれて、プロンプトエンジニアリングプロセスを常に再評価する。

<!--
レッスンのテンプレート
このユニットは、該当する場合、コードチャレンジを提供する必要があります。

課題
Jupyter Notebook にリンクし、指示のコードコメントのみを記述する（コードセクションは空）。

解決策
プロンプトが記入されたノートブックのコピーにリンクし、実行する。
-->

## 課題

おめでとう！レッスンの最後までたどり着きましたね！今までのコンセプトやテクニックを、実際の例で試してみましょう！

今回の課題では、インタラクティブに課題をこなせるJupyter Notebookを使います。また、あなた自身のMarkdownやCodeセルでノートブックを拡張し、あなた自身のアイデアやテクニックを探求することもできます。

### 始めるには、レポをフォークしてください。

- (推奨) GitHub Codespacesを起動します。 
- (または) リポジトリをローカルデバイスにクローンし、Docker Desktopで使用する。
- (あるいは) お好みのNotebook実行環境でNotebookを開きます。

### 次に環境変数を設定します。

- repoルートにある`.env.copy`ファイルを`.env`にコピーし、`OPENAI_API_KEY`の値を記入します。APIキーは[OpenAI Dashboard](https://beta.openai.com/account/api-keys?WT.mc_id=academic-105485-koreyst)で確認できます。

### 次に、Jupyter Notebook を開きます。

- ランタイムカーネルを選択します。オプション 1 または 2 を使用する場合は、開発コンテナが提供するデフォルトの Python 3.10.x カーネルを選択するだけです。

これでエクササイズを実行する準備は完了です。ここでは正解と不正解はないことに注意してください - 試行錯誤してオプションを探索し、与えられたモデルとアプリケーションドメインで何が機能するか直感を構築するだけです。

このため、このレッスンにはコードソリューションセグメントはありません。その代わりに、ノートブックには「My Solution:」というタイトルのMarkdownセルがあり、参考のために1つの出力例を示します。

 <!--
レッスンのテンプレートです：
要約と自習のためのリソースでセクションを囲みます。
-->


## 知識チェック

次のうち、合理的なベストプラクティスに従った良いプロンプトはどれですか？

1. 赤い車の画像を見せてください
2. 車種はボルボ、型式はXC90で、夕日が沈む崖のそばに停まっている赤い車の画像を見せてください。
3. 車種はボルボ、モデルはXC90の赤い車の画像を見せてください。

A: 2は、「何」の詳細を提供し、具体的な内容（どの車でもよいわけではなく、特定のメーカーとモデル）に踏み込んでおり、また全体的な設定も描写しているので、最良のプロンプトです。3も描写が多いので次点。

## チャレンジ

プロンプトで「キュー」のテクニックを活用できるか見てみましょう： ボルボの赤い車の画像を見せてください。という文章を完成させてください。

## よくできました！学習を続ける

プロンプトエンジニアリングのコンセプトについてもっと知りたいですか？[継続学習ページ](../13-continued-learning/README.md?WT.mc_id=academic-105485-koreyst)に行って、このトピックに関する他の素晴らしいリソースを見つけましょう。

レッスン5では、[プロンプトのテクニック](../../../05-advanced-prompts/translations/ja/README.md)について学びます！
