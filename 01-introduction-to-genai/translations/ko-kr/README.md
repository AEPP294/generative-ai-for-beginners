# 생성형 AI와 대형 언어 모델 소개

[![생성형 AI와 대형 언어 모델 소개](../../images/01-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://youtu.be/vf_mZrn8ibc?WT.mc_id=academic-105485-koreyst)

*(위 이미지를 클릭하면 이번 수업의 비디오를 볼 수 있습니다)*

생성형 AI는 텍스트, 이미지, 그리고 다른 종류의 콘텐츠를 생성할 수 있는 인공지능입니다. 이 기술이 멋진 이유는 누구나 텍스트 프롬프트, 즉 자연어로 작성된 문장만으로 AI를 사용할 수 있다는 점입니다. 자바나 SQL 같은 언어를 배울 필요가 없고, 자신의 언어를 사용하여 원하는 것을 말하기만 하면 AI 모델에서 제안을 해줍니다. 보고서를 작성하거나 이해하고, 애플리케이션을 작성하는 등의 작업을 몇 초 만에 처리할 수 있어 그 활용도와 영향력이 매우 크죠.

이 커리큘럼에서는, 스타트업이 생성형 AI를 활용하여 교육계의 새로운 시나리오를 열어가는 방법과 그 적용의 사회적 의미 및 기술적 한계와 연관된 필연적인 과제를 해결하는 방법을 살펴봅니다.

## 소개

이 수업에서 다룰 내용은:

* 비즈니스 시나리오 소개: 우리의 스타트업 아이디어와 미션.
* 생성형 AI와 우리가 어떻게 현재 기술 수준에 도달했는가.
* 대형 언어 모델의 내부 작동 방식.
* 대형 언어 모델의 주요 능력과 실제 사용 사례.

## 학습 목표

이 수업을 완료하면 다음을 이해하게 될것입니다:

* 생성형 AI란 무엇이며 대규모 언어 모델이 어떻게 작동하는지 이해하게 될 것입니다.
* 교육 시나리오에 초점을 맞추어 대형 언어 모델을 어떻게 활용할 수 있는지 이해하게 될 것입니다.

## 시나리오: 우리의 교육 스타트업

생성형 인공 지능(AI)은 한때 불가능하다고 여겨졌던 것의 한계를 뛰어넘는 AI 기술의 결정체입니다. 생성형 AI 모델에는 여러 가지 기능과 응용 분야가 있지만, 이 커리큘럼에서는 가상의 스타트업을 통해 교육에 어떤 혁신을 가져오는지 살펴볼 것입니다. 이 스타트업을 *우리 스타트업*이라고 부르겠습니다. 우리 스타트업은 교육 분야에서 활동하며 다음과 같은 야심찬 임무 설명을 가지고 있습니다.

> *전 세계적으로 학습 접근성을 개선하고, 교육에 대한 공평한 접근을 보장하며, 모든 학습자에게 필요에 따라 개인화된 학습 경험을 제공합니다.*

우리 스타트업 팀은 현대의 가장 강력한 도구 중 하나인 대규모 언어 모델(LLM)을 활용하지 않고는 이 목표를 달성할 수 없다는 것을 잘 알고 있습니다.

생성형 AI는, 학생들이 방대한 양의 정보와 예시를 제공하는 가상 교사를 24시간 마음대로 이용할 수 있게 하고, 선생님들이 혁신적인 도구를 활용하여 학생을 평가하고 피드백을 제공할 수 있게 하므로, 오늘날 우리의 학습방식과 교육방식에 혁명을 가져올 것으로 예상됩니다.

![모니터를 보고 있는 5명의 젊은 학생 - DALLE2의 이미지](../../images/students-by-DALLE2.png?WT.mc_id=academic-105485-koreyst)

먼저 이 커리큘럼에서 사용할 기본 개념과 용어를 정의하겠습니다.

## 우리는 어떻게 생성형 AI를 얻었나?

최근 생성형 AI 모델의 발표로 인해 엄청난 *과대광고*가 쏟아지고 있지만, 이 기술은 수십 년 전부터 연구되어 왔으며, 최초의 연구는 60년대까지 거슬러 올라가야 할 정도 입니다. 이제 AI의 대화가 인간의 인지 능력을 갖추게 된 시점에 이르렀는데, 예를 들어 [OpenAI ChatGPT](https://openai.com/chatgpt) 또는 웹 검색 Bing 챗에 GPT 모델을 사용하는 [Bing Chat](https://www.microsoft.com/edge/features/bing-chat?WT.mc_id=academic-105485-koreyst)에서 볼 수 있듯이 말이 통하는 단계에 이르렀습니다.

조금 거슬러 올라가면, 최초의 AI 프로토타입은 전문가 그룹에서 추출한 지식 베이스를 컴퓨터에 표현하고 이러한 지식 베이스에 의존하는 타이핑 방식의 챗봇으로 구성되었습니다. 지식 베이스의 답변들은 입력 텍스트에 나타나는 키워드에 의해 결정되었습니다. 하지만 곧 타이핑 방식의 챗봇을 사용하는 접근법이 확장성이 떨어지게 된다는 드러났죠.

### AI에 대한 통계적 접근법: 머신러닝

90년대에 텍스트 분석에 통계적 접근 방식이 적용되면서 전환점이 찾아왔습니다. 90년대에 텍스트 분석에 통계적 접근 방식이 적용되면서 전환점이 찾아왔습니다. 이로 인해 머신 러닝이라는 이름으로 알려진 새로운 알고리즘이 개발되었는데, 이 알고리즘은 별도의 프로그래밍 없이도 데이터에서 패턴을 학습할 수 있습니다. 이 접근 방식을 통해 기계가 인간의 언어 이해를 모방할 수 있었습니다: 데이터 쌍으로 구성된 통계 모델을 훈련시켜, 모델이 미지의 입력 텍스트를 사전에 정의된 라벨로 분류할 수 있도록 함으로써, 그 메시지의 의도를 나타내게 됩니다.

### 신경망과 현대의 가상 비서

최근에는 더 많은 양의 데이터와 더 복잡한 연산을 처리할 수 있는 하드웨어의 기술 발전으로 AI 분야의 연구가 활발해지면서 신경망 또는 딥러닝 알고리즘이라고 하는 고급 머신러닝 알고리즘이 개발되었습니다.

신경망 (특히 순환 신경망 - RNNs)은 자연어 처리를 크게 향상시켰으며, 단어의 문장상 문맥을 고려하여 텍스트의 의미를 보다 의미 있게 표현할 수 있게 하였습니다.

신경망(특히 순환 신경망, RNN)은 자연어 처리 능력을 크게 향상시켰으며, 문장에서 단어의 문맥을 고려하면서 보다 의미 있는 방향으로 텍스트의 의미를 표현할 수 있게 하였습니다.

이 기술은 21세기 초에 탄생한 가상 어시스턴트들의 기반 기술로, 인간 언어를 이해하고 요구 사항을 파악하며, 사전에 정의된 스크립트에 따라 응답하거나 타사 서비스를 이용하여 특정 작업을 매우 능숙하게 수행할 수 있게 되었습니다.

### 현재의 생성형 AI

이것이 바로 오늘날 딥러닝의 하위 집합으로 볼 수 있는 생성형 AI가 탄생하게 된 배경입니다.

![AI, ML, DL 그리고 생성형 AI](../../images/AI-diagram.png?WT.mc_id=academic-105485-koreyst)

AI 분야에서 수십 년에 걸친 연구 끝에 *트랜스포머*라는 새로운 모델 아키텍처가 등장하여 훨씬 긴 텍스트 시퀀스를 입력으로 받을 수 있게 됨으로써 RNN의 한계를 극복했습니다. 트랜스포머는 어텐션 메커니즘에 기반하여 모델에 들어오는 입력에 서로 다른 가중치를 부여함으로써 텍스트 시퀀스의 순서와 상관없이 가장 관련성이 높은 정보가 집중된 곳에 '더 많은 주의'를 기울일 수 있습니다.

텍스트 입력과 출력으로 작동하기 때문에 LLM(대규모 언어 모델)이라고도 불리는 대부분의 최신 생성형 AI 모델은 실제로 이 아키텍처를 기반으로 합니다. 책, 기사, 웹사이트 등 다양한 소스의 라벨이 지정되지 않은 방대한 양의 데이터로 학습된 이러한 모델의 흥미로운 점은 다양한 작업에 사용할 수 있고 창의성을 발휘하여 문법적으로 정확한 텍스트를 생성할 수 있다는 것입니다. 결과적으로 입력된 텍스트를 '이해'하는 기계의 능력을 놀라울 정도로 향상시켰을 뿐만 아니라 인간의 언어로 구성된 응답을 생성하는 능력까지 갖추게 된 것입니다.

## 대형 언어 모델은 어떻게 작동하나요?

다음 장에서는 다양한 유형의 생성형 AI 모델을 살펴볼 예정이지만, 여기서는 대규모 언어 모델이 어떻게 작동하는지 OpenAI GPT(Generative Pre-trained Transformer) 모델을 중심으로 살펴보도록 하겠습니다.

* **토크나이저(Tokenizer), 텍스트를 숫자로**: 대규모 언어 모델은 텍스트를 입력으로 받아 텍스트를 출력으로 생성합니다. 하지만 통계 모델이기 때문에 문자열보다는 숫자에 훨씬 더 잘 작동합니다. 그렇기 때문에 모델에 대한 모든 입력은 모델에서 사용되기 전에 먼저 토큰화 도구에 의해 처리됩니다. 토큰은 가변적인 수의 문자로 구성된 텍스트 뭉치이므로 토크나이저의 주요 작업은 입력 값을 토큰 배열로 분할하는 것입니다. 이후 각 토큰은 원본 텍스트 청크의 정수 인코딩인 토큰 인덱스와 매핑됩니다.

![토큰화의 예시](../../images/tokenizer-example.png?WT.mc_id=academic-105485-koreyst)

* **출력 토큰 예측**: n개의 토큰이 입력으로 주어지면(최대 n은 모델마다 다름), 모델은 하나의 토큰을 출력으로 예측할 수 있습니다.  이 예측된 토큰은 다음 단계의 입력에 추가되며, 이런 방식으로 입력이 점차 확장되어 사용자가 한 문장이나 여러 문장의 답을 받을 수 있게 됩니다. 그래서 ChatGPT를 사용해보신 분들은 가끔 대답이 문장 중간에서 멈춘 것처럼 보이는 현상을 경험하셨을 수 있습니다.

* **선택 과정, 확률 분포**: 모델은 현재 텍스트 이후에 나올 토큰을 확률로 선택합니다. 이는 모델이 훈련을 통해 다음에 올 수 있는 모든 토큰의 확률 분포를 예측하기 때문인데요, 결과적으로 확률이 가장 높은 토큰만 선택되는 것은 아닙니다. 선택 과정에 일부 무작위성이 포함되어 있어, 같은 입력에 대해 항상 똑같은 답이 나오지 않습니다. 이런 무작위성은 창의적 사고 과정을 흉내내기 위해 도입된 것으로, '온도(temperature)'라는 설정을 통해 조절할 수 있습니다.

## 우리 스타트업은 어떻게 대형 언어 모델을 활용할 수 있을까요?

이제 대규모 언어 모델의 내부 작동에 대해 더 잘 이해했으니, 비즈니스 시나리오를 염두에 두고 가장 일반적으로 수행할 수 있는 몇 가지 실제적인 예를 살펴보겠습니다.
앞서 대규모 언어 모델의 주요 기능은 *자연어로 작성된 텍스트 입력에서 시작하여 처음부터 텍스트를 생성하는 것*이라고 말씀드렸습니다.

그렇다면 어떤 종류의 텍스트 입력과 출력이 있을까요?
대규모 언어 모델의 입력은 명령어(prompt)라고 하며, 출력은 현재 입력을 완료하기 위해 다음 토큰을 생성하는 모델 메커니즘을 가리키는 용어인 완성(completion)이라고 합니다. 프롬프트가 무엇이며 모델을 최대한 활용할 수 있는 방식으로 프롬프트를 설계하는 방법에 대해 자세히 알아보겠습니다. 하지만 지금은 프롬프트에 다음이 포함될 수 있다고 가정해 보겠습니다:

* 모델에서 예상되는 출력 유형을 지정하는 **지시문(Instruction)**입니다. 이 지시문에는 경우에 따라 몇 가지 예제나 추가 데이터가 포함될 수 있습니다.

    1. 기사, 책, 제품 리뷰 등의 요약, 더불어 비정형 데이터에서 인사이트를 추출.

    ![요약 예시](../../images/summarization-example.png?WT.mc_id=academic-105485-koreyst)

    <br>

    2. 기사, 에세이, 과제 등의 창의적 아이디어 생성과 디자인.

    ![창의적 글쓰기 예시](../../images/creative-writing-example.png?WT.mc_id=academic-105485-koreyst)

    <br>

* 대화 형식으로 질문한 **질문문**.
  
![대화 예시](../../images/conversation-example.png?WT.mc_id=academic-105485-koreyst)

<br>

* 완료해야 할 **텍스트** 조각으로, 글쓰기 도움을 요청하는 내용을 포함하고 있습니다.

![텍스트 완성 예시](../../images/text-completion-example.png?WT.mc_id=academic-105485-koreyst)

<br>

* 설명 및 문서화 요청과 함께 **코드** 또는 특정 작업을 수행하는 코드를 생성해 달라는 요청입니다.

![코딩 예시](../../images/coding-example.png?WT.mc_id=academic-105485-koreyst)

<br>

위의 예는 매우 단순하므로 대규모 언어 모델 기능의 모든 것을 보여주기 위한 것은 아닙니다. 특히 교육 분야의 경우에 한정해서 생성형 AI를 사용할 수 있는 잠재력을 보여주고 싶었을 뿐입니다.

또한, 생성적 AI 모델의 출력은 완벽하지 않으며 때때로 모델의 창조성이 그것에게 반대로 작용하여, 인간 사용자가 현실을 왜곡하는 것으로 해석할 수 있는 단어들의 조합이나, 비방적인 내용을 생성할 수 있습니다. 생성적 AI는 지적이지 않습니다. 적어도 비판적인 사고, 창의적인 사고, 감성 지능을 포괄하는 지능의 더 포괄적인 정의에서는요. 그것은 결정적이지 않으며, 믿음직하지 않습니다. 왜냐하면 허위 참조, 내용, 주장과 같은 제작물이 정확한 정보와 함께 결합되어 설득력 있는 매력적인 방식으로 제시될 수 있기 때문입니다. 다음 수업에서, 우리는 이런 제약들을 모두 다루고, 이들을 어떻게 완화할 수 있는지 살펴볼 것입니다.

또한, 생성형 AI 모델의 출력은 완벽하지 않으며 때로는 모델의 창의성이 역으로 작용하여 사용자가 현실을 왜곡하는 것으로 해석하거나 불쾌감을 줄 수 있는 단어의 조합으로 출력될 수 있습니다. 생성형 AI는 지성을 가졌다고 할 수 없습니다. 적어도 비판적인 사고, 창의적인 추론,  감정을 포함한 보다 포괄적인 지능의 정의에서는요. 왜냐하면 거짓 참조, 내용, 주장과 같은 조작된 내용이 올바른 정보와 결합되어 설득력 있고 자신감 있는 방식으로 답변될 수 있기 때문입니다. 다음 강의에서는, 이러한 한계들을 모두 다루고, 이를 개선하기 위해 무엇을 할 수 있는지 살펴볼 것입니다.

## 과제

과제는 [생성형 AI]((https://en.wikipedia.org/wiki/Generative_artificial_intelligence?WT.mc_id=academic-105485-koreyst))에 대해 자세히 알아보고, 현재 생성형 AI가 없는 영역에서 생성형 AI를 추가할 수 있는 분야를 찾아내는 것입니다. '기존 방식'으로 할 때와 어떤 차이가 있을까요, 이전에는 못했던 일을 할 수 있을까요, 아니면 더 빠르게 할 수 있게될까요? 내가 꿈꾸는 AI 스타트업의 모습에 대해 '문제', 'AI 사용 방법', '영향력' 등의 제목과 옵션으로 사업 계획을 포함해서 300단어 분량의 요약문을 작성해보세요.

이 작업을 완료했다면 Microsoft의 인큐베이터인 [Microsoft for Startups Founders Hub](https://www.microsoft.com/startups?WT.mc_id=academic-105485-koreyst)에 지원할 준비가 된겁니다. Azure, OpenAI, 멘토링 등의 크레딧을 제공하니 확인해 보세요!

## Knowledge check

대규모 언어 모델에 대해 사실인 것은 무엇인가요?

1. 매번 똑같은 답변을 받는다.
1. 숫자를 더하고, 동작하는 코드를 생성하는 등 모든 작업을 완벽하게 수행한다.
1. 같은 프롬프트를 사용해도 답변이 다를 수 있습니다. 텍스트든 코드든 무언가의 초안을 제공하는 데도 탁월합니다. 하지만 결과물은 개선해야 합니다.

답: 3, LLM은 확정적이지 않고 응답이 다양하지만 온도 설정을 통해 그 편차를 제어할 수 있습니다. 또한 모든 작업을 완벽하게 수행하기를 기대해서는 안 되며, 무거운 작업을 대신 해주기 때문에 첫 번째 시도에서 좋은 결과물을 얻은 후 차츰 개선해야 하는 경우가 많습니다.

## 수고하셨습니다! 여정을 계속해보세요.

이 수업을 완료한 후에는 , [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst)을 확인해서 생성형 AI 지식을 계속 쌓아보세요.

수업 2에서는 [다양한 LLM 유형 탐색 및 비교](../../../02-exploring-and-comparing-different-llms/translations/ko-kr/README.md?WT.mc_id=academic-105485-koreyst)하는 방법에 대해 알아보겠습니다!  
